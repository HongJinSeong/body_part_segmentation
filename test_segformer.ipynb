{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5f97d7-2df6-48b1-a78f-043fdc678c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### label 정보\n",
    "#### (배경 - 0 / 몸통 - 1 / 오른손 - 2 / 왼손 - 3 / 왼발 - 4 / 오른발 - 5 / 오른쪽 허벅지 - 6 / 왼쪽 허벅지 - 7 / 오른쪽 종아리 - 8 / 왼쪽 종아리 - 9 / 왼쪽 팔 - 10 / \n",
    "#### 오른쪽 팔 - 11 / 왼쪽 전완 - 12 / 오른쪽 전완 - 13 / 머리 - 14)\n",
    "#### 해당 값이 RGB 값임 ex) 배경 0,0,0\n",
    "### mask 확장자 png input image 확장자 jpg 해깔리지 말것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47533803-cc8c-475b-bcd2-0af970c3d8e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1979/3783462672.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check Pytorch installation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Check MMSegmentation installation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \"\"\"Add helper function to spawn N processes and wait for completion of any of\n\u001b[1;32m     37\u001b[0m them. This depends `mp.get_context` which was added in Python 3.4.\"\"\"\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessContext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mProcessRaisedException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessExitedException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMSegmentation installation\n",
    "import mmseg\n",
    "print(mmseg.__version__)\n",
    "import mmcv\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14576152-10c1-45c8-ab11-8159329507ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a089472-1aae-462d-aaeb-35802a65e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('bg', 'body', 'right_hand', 'left_hand', 'left_leg', 'right_reg', 'right_thigh', 'left_thigh','right_calf','left_calf'\n",
    "           ,'left_arm','right_arm','left_forearm','right_forearm','head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f771648-fb50-40a4-ab29-ea7a1390c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [[0,0,0], [1,1,1], [2,2,2], [3,3,3],[4,4,4], [5,5,5], [6,6,6], [7,7,7], [8,8,8], [9,9,9], [10,10,10], [11,11,11], [12,12,12], [13,13,13], [14,14,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca3c5c-00c0-450f-ae23-61e18f5733a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class body_seg(CustomDataset):\n",
    "  CLASSES = classes\n",
    "  PALETTE = palette\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.jpg', seg_map_suffix='.png', \n",
    "                     split=split, **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c892e2-a9e2-4879-9716-9b23180613e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e758e-4098-46ac-9764-2e42cf2b7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import set_random_seed\n",
    "cfg = Config.fromfile('mmsegmentation/configs/segformer/segformer_mit-b0_512x512_160k_ade20k.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82716716-fce1-4443-a416-dd63474d2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dataset_type = 'body_seg'\n",
    "cfg.data_root = '/root'\n",
    "\n",
    "\n",
    "# Since we use ony one GPU, BN is used instead of SyncBN\n",
    "## encoding 부분은 layer normalization \n",
    "## encoding 이후 ecoder part 부터는 batchnormalization\n",
    "cfg.norm_cfg = dict(type='LN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 15\n",
    "\n",
    "cfg.data.samples_per_gpu = 100\n",
    "cfg.data.workers_per_gpu = 2\n",
    "\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (224, 224)\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(224, 224),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = 'train2014'\n",
    "cfg.data.train.ann_dir = 'train_mask'\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = 'val2014'\n",
    "cfg.data.val.ann_dir = 'val_mask'\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = 'val2014'\n",
    "cfg.data.test.ann_dir = 'val_mask'\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "checkpoint_file = 'pretrained/segformer_mit-b0_512x512_160k_ade20k.pth'\n",
    "cfg.load_from = checkpoint_file\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/train_segforemr'\n",
    "\n",
    "# 1epoch 대략 2600\n",
    "cfg.runner.max_iters = 2600*50\n",
    "cfg.log_config.interval = 1300\n",
    "cfg.evaluation.interval = 2600\n",
    "cfg.checkpoint_config.interval = 2600\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79472b-fa3f-461f-91b6-8626cbba32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "\n",
    "# config_file = 'mmsegmentation/configs/swin/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_22K.py'\n",
    "# model = init_segmentor(config_file, checkpoint_file, device='cuda:0')\n",
    "model = build_segmentor(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22050fa8-6ab7-4f7d-a251-20b1a84b63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint에 config 정보까지 같이 들어 있으나 PALLET 정보가 meta에서 빠져있어서\n",
    "# weight만 따로 불러서 weight만 load 해줌..\n",
    "datas=torch.load('work_dirs/train_segforemr/iter_26000.pth')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7c999-1404-4243-8bf6-028efeca45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(datas)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca8b5e-e515-4355-8fc6-eebb0cde5725",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cfg = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47285e-c1c8-4661-a15e-b0db8f19e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set 받아오기 (나중에는 .py 파일로해서 경로 받을수 있게 해야함 제출양식..)\n",
    "val_ls=[]\n",
    "file = open(\"splits/val.txt\", \"r\")\n",
    "while True:\n",
    "    line = file.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    val_ls.append(line.strip())\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81912903-cbf5-404f-8c6b-45576ad7771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pallete_np=np.array(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f640d-492b-4d09-91a3-ad0b5cf8effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inference_segmentor(model, 'val2014/' + val_ls[0] + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84914947-3df5-4039-9bf6-265740dc519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pallete_np[result[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc715e-df96-4c92-b218-efbe02e77de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as iio\n",
    "\n",
    "iio.imsave('tttt.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61baf3e2-3975-4882-aab9-14b1e2b45658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
