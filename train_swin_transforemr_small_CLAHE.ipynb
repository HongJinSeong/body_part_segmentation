{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5f97d7-2df6-48b1-a78f-043fdc678c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### label 정보\n",
    "#### (배경 - 0 / 몸통 - 1 / 오른손 - 2 / 왼손 - 3 / 왼발 - 4 / 오른발 - 5 / 오른쪽 허벅지 - 6 / 왼쪽 허벅지 - 7 / 오른쪽 종아리 - 8 / 왼쪽 종아리 - 9 / 왼쪽 팔 - 10 / \n",
    "#### 오른쪽 팔 - 11 / 왼쪽 전완 - 12 / 오른쪽 전완 - 13 / 머리 - 14)\n",
    "#### 해당 값이 RGB 값임 ex) 배경 0,0,0\n",
    "### mask 확장자 png input image 확장자 jpg 해깔리지 말것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47533803-cc8c-475b-bcd2-0af970c3d8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0 True\n",
      "0.18.0\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMSegmentation installation\n",
    "import mmseg\n",
    "print(mmseg.__version__)\n",
    "import mmcv\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14576152-10c1-45c8-ab11-8159329507ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a089472-1aae-462d-aaeb-35802a65e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('bg', 'body', 'right_hand', 'left_hand', 'left_leg', 'right_reg', 'right_thigh', 'left_thigh','right_calf','left_calf'\n",
    "           ,'left_arm','right_arm','left_forearm','right_forearm','head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f771648-fb50-40a4-ab29-ea7a1390c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [[0,0,0], [1,1,1], [2,2,2], [3,3,3],[4,4,4], [5,5,5], [6,6,6], [7,7,7], [8,8,8], [9,9,9], [10,10,10], [11,11,11], [12,12,12], [13,13,13], [14,14,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bca3c5c-00c0-450f-ae23-61e18f5733a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class body_seg(CustomDataset):\n",
    "  CLASSES = classes\n",
    "  PALETTE = palette\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.jpg', seg_map_suffix='.png', \n",
    "                     split=split, **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c892e2-a9e2-4879-9716-9b23180613e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf3e758e-4098-46ac-9764-2e42cf2b7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import set_random_seed\n",
    "cfg = Config.fromfile('mmsegmentation/configs/swin/upernet_swin_small_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82716716-fce1-4443-a416-dd63474d2f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "norm_cfg = dict(type='LN', requires_grad=True)\n",
      "backbone_norm_cfg = dict(type='LN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    pretrained='pretrain/swin_small_patch4_window7_224.pth',\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer',\n",
      "        pretrain_img_size=224,\n",
      "        embed_dims=96,\n",
      "        patch_size=4,\n",
      "        window_size=7,\n",
      "        mlp_ratio=4,\n",
      "        depths=[2, 2, 18, 2],\n",
      "        num_heads=[3, 6, 12, 24],\n",
      "        strides=(4, 2, 2, 2),\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        patch_norm=True,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.3,\n",
      "        use_abs_pos_embed=False,\n",
      "        act_cfg=dict(type='GELU'),\n",
      "        norm_cfg=dict(type='LN', requires_grad=True)),\n",
      "    decode_head=dict(\n",
      "        type='UPerHead',\n",
      "        in_channels=[96, 192, 384, 768],\n",
      "        in_index=[0, 1, 2, 3],\n",
      "        pool_scales=(1, 2, 3, 6),\n",
      "        channels=512,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=15,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
      "    auxiliary_head=dict(\n",
      "        type='FCNHead',\n",
      "        in_channels=384,\n",
      "        in_index=2,\n",
      "        channels=256,\n",
      "        num_convs=1,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=15,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'))\n",
      "dataset_type = 'body_seg'\n",
      "data_root = '/root'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "crop_size = (224, 224)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(224, 224), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='CLAHE'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(224, 224), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='CLAHE'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(224, 224),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=24,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='body_seg',\n",
      "        data_root='/root',\n",
      "        img_dir='train2014',\n",
      "        ann_dir='train_mask',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),\n",
      "            dict(type='RandomCrop', crop_size=(224, 224), cat_max_ratio=0.75),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='CLAHE'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size=(224, 224), pad_val=0, seg_pad_val=255),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "        ],\n",
      "        split='splits/train.txt'),\n",
      "    val=dict(\n",
      "        type='body_seg',\n",
      "        data_root='/root',\n",
      "        img_dir='val2014',\n",
      "        ann_dir='val_mask',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='CLAHE'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(224, 224),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        split='splits/val.txt'),\n",
      "    test=dict(\n",
      "        type='body_seg',\n",
      "        data_root='/root',\n",
      "        img_dir='val2014',\n",
      "        ann_dir='val_mask',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='CLAHE'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(224, 224),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        split='splits/val.txt'))\n",
      "log_config = dict(\n",
      "    interval=3610, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'pretrained/upernet_swin_small_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=6e-05,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.01,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0))))\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(\n",
      "    policy='poly',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1500,\n",
      "    warmup_ratio=1e-06,\n",
      "    power=1.0,\n",
      "    min_lr=0.0,\n",
      "    by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=541650)\n",
      "checkpoint_config = dict(by_epoch=False, interval=10833)\n",
      "evaluation = dict(interval=10833, metric='mIoU', pre_eval=True)\n",
      "work_dir = './work_dirs/train_small_CLAHE'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.dataset_type = 'body_seg'\n",
    "cfg.data_root = '/root'\n",
    "\n",
    "\n",
    "# Since we use ony one GPU, BN is used instead of SyncBN\n",
    "## encoding 부분은 layer normalization \n",
    "## encoding 이후 ecoder part 부터는 batchnormalization\n",
    "cfg.norm_cfg = dict(type='LN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.auxiliary_head.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 15\n",
    "cfg.model.auxiliary_head.num_classes = 15\n",
    "\n",
    "cfg.data.samples_per_gpu = 24\n",
    "cfg.data.workers_per_gpu = 2\n",
    "\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (224, 224)\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='CLAHE'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='CLAHE'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(224, 224),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = 'train2014'\n",
    "cfg.data.train.ann_dir = 'train_mask'\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = 'val2014'\n",
    "cfg.data.val.ann_dir = 'val_mask'\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = 'val2014'\n",
    "cfg.data.test.ann_dir = 'val_mask'\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "checkpoint_file = 'pretrained/upernet_swin_small_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K.pth'\n",
    "cfg.load_from = checkpoint_file\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/train_small_CLAHE'\n",
    "\n",
    "# 1epoch 대략 43000\n",
    "cfg.runner.max_iters = 10833*50\n",
    "cfg.log_config.interval = 3610\n",
    "cfg.evaluation.interval = 10833\n",
    "cfg.checkpoint_config.interval = 10833\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79472b-fa3f-461f-91b6-8626cbba32c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/mmcv/utils/misc.py:334: UserWarning: \"flip_ratio\" is deprecated in `RandomFlip.__init__`, please use \"prob\" instead\n",
      "  f'\"{src_arg_name}\" is deprecated in '\n",
      "2021-11-02 00:53:21,753 - mmseg - INFO - Loaded 26437 images\n",
      "/opt/conda/lib/python3.7/site-packages/mmseg/models/backbones/swin.py:553: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n",
      "2021-11-02 00:53:24,376 - mmseg - INFO - Loaded 1508 images\n",
      "2021-11-02 00:53:24,376 - mmseg - INFO - load checkpoint from pretrained/upernet_swin_small_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K.pth\n",
      "2021-11-02 00:53:24,377 - mmseg - INFO - Use load_from_local loader\n",
      "2021-11-02 00:53:24,593 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([150, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([15, 512, 1, 1]).\n",
      "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([150]) from checkpoint, the shape in current model is torch.Size([15]).\n",
      "size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([150, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([15, 256, 1, 1]).\n",
      "size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([150]) from checkpoint, the shape in current model is torch.Size([15]).\n",
      "2021-11-02 00:53:24,612 - mmseg - INFO - Start running, host: root@67a5787c91ba, work_dir: /root/work_dirs/train_small_CLAHE\n",
      "2021-11-02 00:53:24,613 - mmseg - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2021-11-02 00:53:24,613 - mmseg - INFO - workflow: [('train', 1)], max: 541650 iters\n",
      "2021-11-02 00:53:24,614 - mmseg - INFO - Checkpoints will be saved to /root/work_dirs/train_small_CLAHE by HardDiskBackend.\n",
      "2021-11-02 01:51:28,632 - mmseg - INFO - Iter [3610/541650]\tlr: 5.960e-05, eta: 6 days, 0:14:04, time: 0.965, data_time: 0.006, memory: 8758, decode.loss_ce: 0.4465, decode.acc_seg: 68.7804, aux.loss_ce: 0.2206, aux.acc_seg: 66.5478, loss: 0.6671\n",
      "2021-11-02 02:49:32,875 - mmseg - INFO - Iter [7220/541650]\tlr: 5.920e-05, eta: 5 days, 23:16:25, time: 0.965, data_time: 0.006, memory: 8758, decode.loss_ce: 0.2849, decode.acc_seg: 72.4055, aux.loss_ce: 0.1238, aux.acc_seg: 71.8560, loss: 0.4087\n"
     ]
    }
   ],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "\n",
    "# config_file = 'mmsegmentation/configs/swin/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_22K.py'\n",
    "# model = init_segmentor(config_file, checkpoint_file, device='cuda:0')\n",
    "model = build_segmentor(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22050fa8-6ab7-4f7d-a251-20b1a84b63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7c999-1404-4243-8bf6-028efeca45a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
