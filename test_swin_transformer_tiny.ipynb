{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8f5f97d7-2df6-48b1-a78f-043fdc678c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### label 정보\n",
    "#### (배경 - 0 / 몸통 - 1 / 오른손 - 2 / 왼손 - 3 / 왼발 - 4 / 오른발 - 5 / 오른쪽 허벅지 - 6 / 왼쪽 허벅지 - 7 / 오른쪽 종아리 - 8 / 왼쪽 종아리 - 9 / 왼쪽 팔 - 10 / \n",
    "#### 오른쪽 팔 - 11 / 왼쪽 전완 - 12 / 오른쪽 전완 - 13 / 머리 - 14)\n",
    "#### 해당 값이 RGB 값임 ex) 배경 0,0,0\n",
    "### mask 확장자 png input image 확장자 jpg 해깔리지 말것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "47533803-cc8c-475b-bcd2-0af970c3d8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0 True\n",
      "0.18.0\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMSegmentation installation\n",
    "import mmseg\n",
    "print(mmseg.__version__)\n",
    "import mmcv\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14576152-10c1-45c8-ab11-8159329507ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3a089472-1aae-462d-aaeb-35802a65e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('bg', 'body', 'right_hand', 'left_hand', 'left_leg', 'right_reg', 'right_thigh', 'left_thigh','right_calf','left_calf'\n",
    "           ,'left_arm','right_arm','left_forearm','right_forearm','head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5f771648-fb50-40a4-ab29-ea7a1390c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [[0,0,0], [1,1,1], [2,2,2], [3,3,3],[4,4,4], [5,5,5], [6,6,6], [7,7,7], [8,8,8], [9,9,9], [10,10,10], [11,11,11], [12,12,12], [13,13,13], [14,14,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5bca3c5c-00c0-450f-ae23-61e18f5733a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'body_seg is already registered in dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1852/1265169064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mbody_seg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCustomDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mCLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mPALETTE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36m_register\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             self._register_module(\n\u001b[0;32m--> 312\u001b[0;31m                 module_class=cls, module_name=name, force=force)\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36m_register_module\u001b[0;34m(self, module_class, module_name, force)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 raise KeyError(f'{name} is already registered '\n\u001b[0m\u001b[1;32m    247\u001b[0m                                f'in {self.name}')\n\u001b[1;32m    248\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'body_seg is already registered in dataset'"
     ]
    }
   ],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class body_seg(CustomDataset):\n",
    "  CLASSES = classes\n",
    "  PALETTE = palette\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.jpg', seg_map_suffix='.png', \n",
    "                     split=split, **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c892e2-a9e2-4879-9716-9b23180613e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bf3e758e-4098-46ac-9764-2e42cf2b7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import set_random_seed\n",
    "cfg = Config.fromfile('mmsegmentation/configs/swin/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "82716716-fce1-4443-a416-dd63474d2f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "norm_cfg = dict(type='LN', requires_grad=True)\n",
      "backbone_norm_cfg = dict(type='LN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    pretrained='pretrain/swin_tiny_patch4_window7_224.pth',\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer',\n",
      "        pretrain_img_size=224,\n",
      "        embed_dims=96,\n",
      "        patch_size=4,\n",
      "        window_size=7,\n",
      "        mlp_ratio=4,\n",
      "        depths=[2, 2, 6, 2],\n",
      "        num_heads=[3, 6, 12, 24],\n",
      "        strides=(4, 2, 2, 2),\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        patch_norm=True,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.3,\n",
      "        use_abs_pos_embed=False,\n",
      "        act_cfg=dict(type='GELU'),\n",
      "        norm_cfg=dict(type='LN', requires_grad=True)),\n",
      "    decode_head=dict(\n",
      "        type='UPerHead',\n",
      "        in_channels=[96, 192, 384, 768],\n",
      "        in_index=[0, 1, 2, 3],\n",
      "        pool_scales=(1, 2, 3, 6),\n",
      "        channels=512,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=15,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
      "    auxiliary_head=dict(\n",
      "        type='FCNHead',\n",
      "        in_channels=384,\n",
      "        in_index=2,\n",
      "        channels=256,\n",
      "        num_convs=1,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=15,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'))\n",
      "dataset_type = 'body_seg'\n",
      "data_root = '/root'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "crop_size = (224, 224)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(224, 224), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(224, 224), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(224, 224),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=24,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='ADE20KDataset',\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        img_dir='images/training',\n",
      "        ann_dir='annotations/training',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', reduce_zero_label=True),\n",
      "            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n",
      "            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
      "            dict(type='RandomFlip', prob=0.5),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='ADE20KDataset',\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        img_dir='images/validation',\n",
      "        ann_dir='annotations/validation',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(2048, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='ADE20KDataset',\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        img_dir='images/validation',\n",
      "        ann_dir='annotations/validation',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(224, 224),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "log_config = dict(\n",
      "    interval=3610, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'pretrained/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=6e-05,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.01,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0))))\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(\n",
      "    policy='poly',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1500,\n",
      "    warmup_ratio=1e-06,\n",
      "    power=1.0,\n",
      "    min_lr=0.0,\n",
      "    by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=541650)\n",
      "checkpoint_config = dict(by_epoch=False, interval=10833)\n",
      "evaluation = dict(interval=10833, metric='mIoU', pre_eval=True)\n",
      "work_dir = './work_dirs/train_tiny'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.dataset_type = 'body_seg'\n",
    "cfg.data_root = '/root'\n",
    "\n",
    "\n",
    "# Since we use ony one GPU, BN is used instead of SyncBN\n",
    "## encoding 부분은 layer normalization \n",
    "## encoding 이후 ecoder part 부터는 batchnormalization\n",
    "cfg.norm_cfg = dict(type='LN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.auxiliary_head.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 15\n",
    "cfg.model.auxiliary_head.num_classes = 15\n",
    "\n",
    "cfg.data.samples_per_gpu = 24\n",
    "cfg.data.workers_per_gpu = 2\n",
    "\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (224, 224)\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(224, 224),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "# cfg.data.train.type = cfg.dataset_type\n",
    "# cfg.data.train.data_root = cfg.data_root\n",
    "# cfg.data.train.img_dir = 'train2014'\n",
    "# cfg.data.train.ann_dir = 'train_mask'\n",
    "# cfg.data.train.pipeline = cfg.train_pipeline\n",
    "# cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "# cfg.data.val.type = cfg.dataset_type\n",
    "# cfg.data.val.data_root = cfg.data_root\n",
    "# cfg.data.val.img_dir = 'val2014'\n",
    "# cfg.data.val.ann_dir = 'val_mask'\n",
    "# cfg.data.val.pipeline = cfg.test_pipeline\n",
    "# cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "\n",
    "# cfg.data.test.type = cfg.dataset_type\n",
    "# cfg.data.test.data_root = cfg.data_root\n",
    "# cfg.data.test.img_dir = 'val2014'\n",
    "# cfg.data.test.ann_dir = 'val_mask'\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "# cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "checkpoint_file = 'pretrained/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K.pth'\n",
    "cfg.load_from = checkpoint_file\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/train_tiny'\n",
    "\n",
    "# 1epoch 대략 43000\n",
    "cfg.runner.max_iters = 10833*50\n",
    "cfg.log_config.interval = 3610\n",
    "cfg.evaluation.interval = 10833\n",
    "cfg.checkpoint_config.interval = 10833\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ad79472b-fa3f-461f-91b6-8626cbba32c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([150, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([15, 512, 1, 1]).\n",
      "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([150]) from checkpoint, the shape in current model is torch.Size([15]).\n",
      "size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([150, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([15, 256, 1, 1]).\n",
      "size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([150]) from checkpoint, the shape in current model is torch.Size([15]).\n"
     ]
    }
   ],
   "source": [
    "#train시에 사용했던 기본 config 그대로 load해줌 \n",
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "# datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "\n",
    "# config_file = 'mmsegmentation/configs/swin/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_22K.py'\n",
    "# model = init_segmentor(config_file, checkpoint_file, device='cuda:0')\n",
    "model = init_segmentor(cfg, checkpoint_file, device='cuda:0')\n",
    "\n",
    "# model = build_segmentor(\n",
    "#     cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22050fa8-6ab7-4f7d-a251-20b1a84b63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint에 config 정보까지 같이 들어 있으나 PALLET 정보가 meta에서 빠져있어서\n",
    "# weight만 따로 불러서 weight만 load 해줌..\n",
    "datas=torch.load('work_dirs/train_tiny/iter_227493.pth')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1cc7c999-1404-4243-8bf6-028efeca45a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (backbone): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (adap_padding): AdaptivePadding()\n",
       "      (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (drop_after_pos): Dropout(p=0.0, inplace=False)\n",
       "    (stages): ModuleList(\n",
       "      (0): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=384, out_features=96, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): SwinBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=384, out_features=96, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (adap_padding): AdaptivePadding()\n",
       "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
       "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): SwinBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (adap_padding): AdaptivePadding()\n",
       "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): SwinBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): SwinBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (3): SwinBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (4): SwinBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (5): SwinBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (adap_padding): AdaptivePadding()\n",
       "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
       "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): SwinBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (activate): GELU()\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decode_head): UPerHead(\n",
       "    input_transform=multiple_select, ignore_index=255, align_corners=False\n",
       "    (loss_decode): ModuleList(\n",
       "      (0): CrossEntropyLoss()\n",
       "    )\n",
       "    (conv_seg): Conv2d(512, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (psp_modules): PPM(\n",
       "      (0): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=2)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=3)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=6)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottleneck): ConvModule(\n",
       "      (conv): Conv2d(2816, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (fpn_bottleneck): ConvModule(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
       "  (auxiliary_head): FCNHead(\n",
       "    input_transform=None, ignore_index=255, align_corners=False\n",
       "    (loss_decode): ModuleList(\n",
       "      (0): CrossEntropyLoss()\n",
       "    )\n",
       "    (conv_seg): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (convs): Sequential(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(datas)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fce33326-2854-4b9d-a7ee-14b4bd4024ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set 받아오기 (나중에는 .py 파일로해서 경로 받을수 있게 해야함 제출양식..)\n",
    "val_ls=[]\n",
    "file = open(\"splits/val.txt\", \"r\")\n",
    "while True:\n",
    "    line = file.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    val_ls.append(line.strip())\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d8f8f077-b9ee-4bf0-bc71-e9995f1ec64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cfg = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0c679b28-6816-4456-a649-08d2eda02f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inference_segmentor(model, 'val2014/' + val_ls[0] + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "115a2513-336e-4baf-80a7-ce78ea7d6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pallete_np=np.array(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0b7f3e87-068e-45d0-9fb2-0fd0f7d3a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pallete_np[result[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ca2374c5-5cc7-494b-87bc-490563ff8a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: tttt.jpg is a low contrast image\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "Lossy conversion from int64 to uint8. Range [0, 14]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "import skimage.io as iio\n",
    "\n",
    "iio.imsave('tttt.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5619aee7-c5db-47ba-b3de-9f007dce8371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffacaec-e243-4216-8141-bae8cfc81290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10021057-9551-4a6b-abf0-f0d5f92609c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1820d559-0f6c-4f95-9963-e25ab7b5895c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01aa532-95f3-45dc-9a53-5f838a2e8bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d269cb-03ca-4588-b7f3-49c2a61361b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
