{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5f97d7-2df6-48b1-a78f-043fdc678c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### label 정보\n",
    "#### (배경 - 0 / 몸통 - 1 / 오른손 - 2 / 왼손 - 3 / 왼발 - 4 / 오른발 - 5 / 오른쪽 허벅지 - 6 / 왼쪽 허벅지 - 7 / 오른쪽 종아리 - 8 / 왼쪽 종아리 - 9 / 왼쪽 팔 - 10 / \n",
    "#### 오른쪽 팔 - 11 / 왼쪽 전완 - 12 / 오른쪽 전완 - 13 / 머리 - 14)\n",
    "#### 해당 값이 RGB 값임 ex) 배경 0,0,0\n",
    "### mask 확장자 png input image 확장자 jpg 해깔리지 말것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47533803-cc8c-475b-bcd2-0af970c3d8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0 True\n",
      "0.18.0\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMSegmentation installation\n",
    "import mmseg\n",
    "print(mmseg.__version__)\n",
    "import mmcv\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14576152-10c1-45c8-ab11-8159329507ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette\n",
    "## ver2용 추가\n",
    "## 기존 mmsegmentation에 없거나 기능수정한 것 따로 data pipeline set\n",
    "from custom_data_pipeline import CutOut,RandomAffine,CustomRandomFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a089472-1aae-462d-aaeb-35802a65e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('bg', 'body', 'right_hand', 'left_hand', 'left_leg', 'right_reg', 'right_thigh', 'left_thigh','right_calf','left_calf'\n",
    "           ,'left_arm','right_arm','left_forearm','right_forearm','head')\n",
    "## ver2용 추가 \n",
    "flip_pair=[[2,3],[4,5],[6,7],[8,9],[10,11],[12,13]]  ##flip pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f771648-fb50-40a4-ab29-ea7a1390c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [[0,0,0], [1,1,1], [2,2,2], [3,3,3],[4,4,4], [5,5,5], [6,6,6], [7,7,7], [8,8,8], [9,9,9], [10,10,10], [11,11,11], [12,12,12], [13,13,13], [14,14,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c892e2-a9e2-4879-9716-9b23180613e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3e758e-4098-46ac-9764-2e42cf2b7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import set_random_seed\n",
    "cfg = Config.fromfile('mmsegmentation/configs/swin/upernet_swin_small_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82716716-fce1-4443-a416-dd63474d2f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "norm_cfg = dict(type='LN', requires_grad=True)\n",
      "backbone_norm_cfg = dict(type='LN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    pretrained='pretrain/swin_small_patch4_window7_224.pth',\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer',\n",
      "        pretrain_img_size=224,\n",
      "        embed_dims=96,\n",
      "        patch_size=4,\n",
      "        window_size=7,\n",
      "        mlp_ratio=4,\n",
      "        depths=[2, 2, 18, 2],\n",
      "        num_heads=[3, 6, 12, 24],\n",
      "        strides=(4, 2, 2, 2),\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        patch_norm=True,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.3,\n",
      "        use_abs_pos_embed=False,\n",
      "        act_cfg=dict(type='GELU'),\n",
      "        norm_cfg=dict(type='LN', requires_grad=True)),\n",
      "    decode_head=dict(\n",
      "        type='UPerHead',\n",
      "        in_channels=[96, 192, 384, 768],\n",
      "        in_index=[0, 1, 2, 3],\n",
      "        pool_scales=(1, 2, 3, 6),\n",
      "        channels=512,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=15,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
      "    auxiliary_head=dict(\n",
      "        type='FCNHead',\n",
      "        in_channels=384,\n",
      "        in_index=2,\n",
      "        channels=256,\n",
      "        num_convs=1,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=15,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'))\n",
      "dataset_type = 'body_seg'\n",
      "data_root = '/root'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "crop_size = (224, 224)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(224, 224), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', flip_ratio=0.0),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='CustomRandomFlip',\n",
      "        prob=0.5,\n",
      "        flip_pair=[[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13]]),\n",
      "    dict(\n",
      "        type='CutOut',\n",
      "        n_holes=(0, 4),\n",
      "        cutout_shape=[(16, 16), (32, 32), (48, 48)]),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(224, 224), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(224, 224),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=24,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='body_seg',\n",
      "        data_root='/root',\n",
      "        img_dir='train2014',\n",
      "        ann_dir='train_mask',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),\n",
      "            dict(type='RandomCrop', crop_size=(224, 224), cat_max_ratio=0.75),\n",
      "            dict(type='RandomFlip', flip_ratio=0.0),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='CustomRandomFlip',\n",
      "                prob=0.5,\n",
      "                flip_pair=[[2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12,\n",
      "                                                                      13]]),\n",
      "            dict(\n",
      "                type='CutOut',\n",
      "                n_holes=(0, 4),\n",
      "                cutout_shape=[(16, 16), (32, 32), (48, 48)]),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size=(224, 224), pad_val=0, seg_pad_val=255),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "        ],\n",
      "        split='splits/train.txt'),\n",
      "    val=dict(\n",
      "        type='body_seg',\n",
      "        data_root='/root',\n",
      "        img_dir='val2014',\n",
      "        ann_dir='val_mask',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(224, 224),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        split='splits/val.txt'),\n",
      "    test=dict(\n",
      "        type='body_seg',\n",
      "        data_root='/root',\n",
      "        img_dir='val2014',\n",
      "        ann_dir='val_mask',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(224, 224),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        split='splits/val.txt'))\n",
      "log_config = dict(\n",
      "    interval=542, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'pretrained/iter_173328.pt'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=0.0001,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.0,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0))))\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=216800)\n",
      "checkpoint_config = dict(by_epoch=False, interval=1084)\n",
      "evaluation = dict(interval=1084, metric='mIoU', pre_eval=True)\n",
      "work_dir = './work_dirs/train_small_ver2'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.dataset_type = 'body_seg'\n",
    "cfg.data_root = '/root'\n",
    "\n",
    "\n",
    "# Since we use ony one GPU, BN is used instead of SyncBN\n",
    "## encoding 부분은 layer normalization \n",
    "## encoding 이후 ecoder part 부터는 batchnormalization\n",
    "cfg.norm_cfg = dict(type='LN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.auxiliary_head.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 15\n",
    "cfg.model.auxiliary_head.num_classes = 15\n",
    "\n",
    "cfg.data.samples_per_gpu = 24\n",
    "cfg.data.workers_per_gpu = 2\n",
    "\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (224, 224)\n",
    "\n",
    "# 기존 \n",
    "# cfg.train_pipeline = [\n",
    "#     dict(type='LoadImageFromFile'),\n",
    "#     dict(type='LoadAnnotations'),\n",
    "#     dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),\n",
    "#     dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "#     dict(type='RandomFlip', flip_ratio=0.5),\n",
    "#     dict(type='PhotoMetricDistortion'),\n",
    "#     dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "#     dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "#     dict(type='DefaultFormatBundle'),\n",
    "#     dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "# ]\n",
    "\n",
    "### 수정 version 2\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(256, 256), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.0),   # flip시 pair부위가 뒤집어져야 하기 때문에 custom flip 적용 \n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    ##### ver 2용 수정 #########\n",
    "    dict(type='CustomRandomFlip', prob=0.5, flip_pair=flip_pair), #기존 flip과 동일하게 horizontal flip 하면서 pair를 맞춰주는 거만 추가함 \n",
    "    dict(type='CutOut', n_holes=(0,4),cutout_shape=[(16,16),(32,32),(48,48)]),   ## 추가 (Cutout이 아닌 Random erase 형태로 적용함)\n",
    "    #dict(type='RandomAffine'),              ## 추가 (affine transform은 조금 강하게 줬을 때 학습 경향이 너무 안좋아져서 default로 사용하는 것으로..)\n",
    "                                            ## affine transform은 아주 약하게 input에만 먹이고 label은 적용 안하는 것으로..(라벨까지 적용시 학습경향이 안좋음)\n",
    "    ##### ver 2용 수정 #########\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "## test시간 아껴야 되서 TTA나 후처리는 실제 inference시에만 적용 \n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(224, 224),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = 'train2014'\n",
    "cfg.data.train.ann_dir = 'train_mask'\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = 'val2014'\n",
    "cfg.data.val.ann_dir = 'val_mask'\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = 'val2014'\n",
    "cfg.data.test.ann_dir = 'val_mask'\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "## 강한 augmentation 주기 이전에 best validation iou score 기반 weight\n",
    "# checkpoint_file = 'pretrained/upernet_swin_small_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K.pth'\n",
    "checkpoint_file = 'pretrained/iter_173328.pt'\n",
    "cfg.load_from = checkpoint_file\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/train_small_ver2'\n",
    "\n",
    "# 1epoch 대략 43000\n",
    "cfg.runner.max_iters = 1084*200\n",
    "cfg.log_config.interval = 542\n",
    "cfg.evaluation.interval = 1084\n",
    "cfg.checkpoint_config.interval = 1084\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "\n",
    "cfg.optimizer = dict(\n",
    "    type='AdamW',\n",
    "    lr=0.0001,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=0.,\n",
    "    paramwise_cfg=dict(\n",
    "        custom_keys={\n",
    "            'absolute_pos_embed': dict(decay_mult=0.),\n",
    "            'relative_position_bias_table': dict(decay_mult=0.),\n",
    "            'norm': dict(decay_mult=0.)\n",
    "        }))\n",
    "\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bca3c5c-00c0-450f-ae23-61e18f5733a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class body_seg(CustomDataset):\n",
    "  CLASSES = classes\n",
    "  PALETTE = palette\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.jpg', seg_map_suffix='.png', \n",
    "                     split=split, **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad79472b-fa3f-461f-91b6-8626cbba32c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/mmcv/utils/misc.py:334: UserWarning: \"flip_ratio\" is deprecated in `RandomFlip.__init__`, please use \"prob\" instead\n",
      "  f'\"{src_arg_name}\" is deprecated in '\n",
      "2021-11-16 05:11:30,381 - mmseg - INFO - Loaded 26437 images\n",
      "/opt/conda/lib/python3.7/site-packages/mmseg/models/backbones/swin.py:553: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "\n",
    "# config_file = 'mmsegmentation/configs/swin/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_22K.py'\n",
    "# model = init_segmentor(config_file, checkpoint_file, device='cuda:0')\n",
    "model = build_segmentor(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "#학습시켰던 weight만 load 해줌\n",
    "weights=torch.load('pretrained/iter_173328.pt')\n",
    "model.load_state_dict(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22050fa8-6ab7-4f7d-a251-20b1a84b63df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 05:11:34,239 - mmseg - INFO - Loaded 1908 images\n",
      "2021-11-16 05:11:34,240 - mmseg - INFO - load checkpoint from pretrained/iter_173328.pt\n",
      "2021-11-16 05:11:34,240 - mmseg - INFO - Use load_from_local loader\n",
      "2021-11-16 05:11:34,461 - mmseg - INFO - Start running, host: root@67a5787c91ba, work_dir: /root/work_dirs/train_small_ver2\n",
      "2021-11-16 05:11:34,462 - mmseg - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2021-11-16 05:11:34,462 - mmseg - INFO - workflow: [('train', 1)], max: 216800 iters\n",
      "2021-11-16 05:11:34,463 - mmseg - INFO - Checkpoints will be saved to /root/work_dirs/train_small_ver2 by HardDiskBackend.\n",
      "2021-11-16 05:20:15,841 - mmseg - INFO - Iter [542/216800]\tlr: 1.000e-04, eta: 2 days, 9:46:17, time: 0.962, data_time: 0.007, memory: 8758, decode.loss_ce: 0.1519, decode.acc_seg: 77.1300, aux.loss_ce: 0.0802, aux.acc_seg: 75.3514, loss: 0.2321\n",
      "2021-11-16 05:28:55,836 - mmseg - INFO - Saving checkpoint at 1084 iterations\n",
      "2021-11-16 05:28:57,423 - mmseg - INFO - Iter [1084/216800]\tlr: 1.000e-04, eta: 2 days, 9:38:43, time: 0.962, data_time: 0.006, memory: 8758, decode.loss_ce: 0.1417, decode.acc_seg: 77.2657, aux.loss_ce: 0.0744, aux.acc_seg: 75.6779, loss: 0.2161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0/1908, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 1908/1908, 12.6 task/s, elapsed: 151s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 05:31:29,662 - mmseg - INFO - per class results:\n",
      "2021-11-16 05:31:29,664 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 95.45 | 98.49 |\n",
      "|      body     | 73.31 | 79.91 |\n",
      "|   right_hand  | 14.47 | 24.65 |\n",
      "|   left_hand   | 11.59 | 21.51 |\n",
      "|    left_leg   |  7.1  | 11.32 |\n",
      "|   right_reg   |  6.38 |  10.6 |\n",
      "|  right_thigh  |  8.14 | 14.35 |\n",
      "|   left_thigh  |  8.98 | 17.13 |\n",
      "|   right_calf  |  8.26 | 15.98 |\n",
      "|   left_calf   |  7.9  | 14.65 |\n",
      "|    left_arm   | 11.31 |  21.4 |\n",
      "|   right_arm   |  13.1 | 20.98 |\n",
      "|  left_forearm |  9.98 | 19.29 |\n",
      "| right_forearm |  11.4 | 20.19 |\n",
      "|      head     | 66.25 | 73.76 |\n",
      "+---------------+-------+-------+\n",
      "2021-11-16 05:31:29,665 - mmseg - INFO - Summary:\n",
      "2021-11-16 05:31:29,665 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 87.73 | 23.57 | 30.95 |\n",
      "+-------+-------+-------+\n",
      "2021-11-16 05:31:29,670 - mmseg - INFO - Iter(val) [1908]\taAcc: 0.8773, mIoU: 0.2357, mAcc: 0.3095, IoU.bg: 0.9545, IoU.body: 0.7331, IoU.right_hand: 0.1447, IoU.left_hand: 0.1159, IoU.left_leg: 0.0710, IoU.right_reg: 0.0638, IoU.right_thigh: 0.0814, IoU.left_thigh: 0.0898, IoU.right_calf: 0.0826, IoU.left_calf: 0.0790, IoU.left_arm: 0.1131, IoU.right_arm: 0.1310, IoU.left_forearm: 0.0998, IoU.right_forearm: 0.1140, IoU.head: 0.6625, Acc.bg: 0.9849, Acc.body: 0.7991, Acc.right_hand: 0.2465, Acc.left_hand: 0.2151, Acc.left_leg: 0.1132, Acc.right_reg: 0.1060, Acc.right_thigh: 0.1435, Acc.left_thigh: 0.1713, Acc.right_calf: 0.1598, Acc.left_calf: 0.1465, Acc.left_arm: 0.2140, Acc.right_arm: 0.2098, Acc.left_forearm: 0.1929, Acc.right_forearm: 0.2019, Acc.head: 0.7376\n",
      "2021-11-16 05:40:10,900 - mmseg - INFO - Iter [1626/216800]\tlr: 1.000e-04, eta: 2 days, 15:05:23, time: 1.243, data_time: 0.288, memory: 8758, decode.loss_ce: 0.1382, decode.acc_seg: 77.4034, aux.loss_ce: 0.0725, aux.acc_seg: 75.8704, loss: 0.2107\n",
      "2021-11-16 05:48:51,781 - mmseg - INFO - Saving checkpoint at 2168 iterations\n",
      "2021-11-16 05:48:53,690 - mmseg - INFO - Iter [2168/216800]\tlr: 1.000e-04, eta: 2 days, 13:34:29, time: 0.965, data_time: 0.006, memory: 8758, decode.loss_ce: 0.1369, decode.acc_seg: 77.3830, aux.loss_ce: 0.0717, aux.acc_seg: 75.8880, loss: 0.2086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 1908/1908, 12.7 task/s, elapsed: 151s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 05:51:24,829 - mmseg - INFO - per class results:\n",
      "2021-11-16 05:51:24,830 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 95.23 | 98.58 |\n",
      "|      body     | 71.89 | 78.26 |\n",
      "|   right_hand  | 14.68 | 24.97 |\n",
      "|   left_hand   | 12.47 | 23.54 |\n",
      "|    left_leg   |  9.01 | 14.46 |\n",
      "|   right_reg   |  7.03 | 11.62 |\n",
      "|  right_thigh  |  9.17 | 15.87 |\n",
      "|   left_thigh  | 10.77 | 20.47 |\n",
      "|   right_calf  |  8.72 | 15.64 |\n",
      "|   left_calf   | 10.29 |  18.5 |\n",
      "|    left_arm   | 12.46 | 22.98 |\n",
      "|   right_arm   | 13.65 | 21.57 |\n",
      "|  left_forearm |  10.9 | 20.89 |\n",
      "| right_forearm | 11.92 | 20.66 |\n",
      "|      head     | 65.08 |  72.2 |\n",
      "+---------------+-------+-------+\n",
      "2021-11-16 05:51:24,831 - mmseg - INFO - Summary:\n",
      "2021-11-16 05:51:24,831 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 87.84 | 24.22 | 32.01 |\n",
      "+-------+-------+-------+\n",
      "2021-11-16 05:51:24,843 - mmseg - INFO - Iter(val) [1908]\taAcc: 0.8784, mIoU: 0.2422, mAcc: 0.3201, IoU.bg: 0.9523, IoU.body: 0.7189, IoU.right_hand: 0.1468, IoU.left_hand: 0.1247, IoU.left_leg: 0.0901, IoU.right_reg: 0.0703, IoU.right_thigh: 0.0917, IoU.left_thigh: 0.1077, IoU.right_calf: 0.0872, IoU.left_calf: 0.1029, IoU.left_arm: 0.1246, IoU.right_arm: 0.1365, IoU.left_forearm: 0.1090, IoU.right_forearm: 0.1192, IoU.head: 0.6508, Acc.bg: 0.9858, Acc.body: 0.7826, Acc.right_hand: 0.2497, Acc.left_hand: 0.2354, Acc.left_leg: 0.1446, Acc.right_reg: 0.1162, Acc.right_thigh: 0.1587, Acc.left_thigh: 0.2047, Acc.right_calf: 0.1564, Acc.left_calf: 0.1850, Acc.left_arm: 0.2298, Acc.right_arm: 0.2157, Acc.left_forearm: 0.2089, Acc.right_forearm: 0.2066, Acc.head: 0.7220\n",
      "2021-11-16 06:00:06,286 - mmseg - INFO - Iter [2710/216800]\tlr: 1.000e-04, eta: 2 days, 15:53:42, time: 1.241, data_time: 0.286, memory: 8758, decode.loss_ce: 0.1347, decode.acc_seg: 77.5566, aux.loss_ce: 0.0705, aux.acc_seg: 76.0955, loss: 0.2053\n",
      "2021-11-16 06:08:47,307 - mmseg - INFO - Saving checkpoint at 3252 iterations\n",
      "2021-11-16 06:08:49,006 - mmseg - INFO - Iter [3252/216800]\tlr: 1.000e-04, eta: 2 days, 14:38:45, time: 0.964, data_time: 0.006, memory: 8758, decode.loss_ce: 0.1362, decode.acc_seg: 77.4393, aux.loss_ce: 0.0711, aux.acc_seg: 75.9712, loss: 0.2074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 1908/1908, 12.5 task/s, elapsed: 153s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 06:11:21,595 - mmseg - INFO - per class results:\n",
      "2021-11-16 06:11:21,596 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 95.22 | 98.56 |\n",
      "|      body     | 71.71 | 77.57 |\n",
      "|   right_hand  | 14.39 | 24.88 |\n",
      "|   left_hand   | 11.84 | 22.27 |\n",
      "|    left_leg   |  9.31 |  15.3 |\n",
      "|   right_reg   |  5.29 |  8.46 |\n",
      "|  right_thigh  |  7.94 | 13.81 |\n",
      "|   left_thigh  |  9.58 |  18.5 |\n",
      "|   right_calf  |  7.71 | 14.12 |\n",
      "|   left_calf   |  9.56 | 17.55 |\n",
      "|    left_arm   | 11.67 | 21.82 |\n",
      "|   right_arm   | 13.85 | 22.85 |\n",
      "|  left_forearm |  10.0 | 18.54 |\n",
      "| right_forearm | 12.07 | 21.27 |\n",
      "|      head     | 65.25 | 72.66 |\n",
      "+---------------+-------+-------+\n",
      "2021-11-16 06:11:21,597 - mmseg - INFO - Summary:\n",
      "2021-11-16 06:11:21,597 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 87.66 | 23.69 | 31.21 |\n",
      "+-------+-------+-------+\n",
      "2021-11-16 06:11:21,600 - mmseg - INFO - Iter(val) [1908]\taAcc: 0.8766, mIoU: 0.2369, mAcc: 0.3121, IoU.bg: 0.9522, IoU.body: 0.7171, IoU.right_hand: 0.1439, IoU.left_hand: 0.1184, IoU.left_leg: 0.0931, IoU.right_reg: 0.0529, IoU.right_thigh: 0.0794, IoU.left_thigh: 0.0958, IoU.right_calf: 0.0771, IoU.left_calf: 0.0956, IoU.left_arm: 0.1167, IoU.right_arm: 0.1385, IoU.left_forearm: 0.1000, IoU.right_forearm: 0.1207, IoU.head: 0.6525, Acc.bg: 0.9856, Acc.body: 0.7757, Acc.right_hand: 0.2488, Acc.left_hand: 0.2227, Acc.left_leg: 0.1530, Acc.right_reg: 0.0846, Acc.right_thigh: 0.1381, Acc.left_thigh: 0.1850, Acc.right_calf: 0.1412, Acc.left_calf: 0.1755, Acc.left_arm: 0.2182, Acc.right_arm: 0.2285, Acc.left_forearm: 0.1854, Acc.right_forearm: 0.2127, Acc.head: 0.7266\n",
      "2021-11-16 06:20:02,935 - mmseg - INFO - Iter [3794/216800]\tlr: 1.000e-04, eta: 2 days, 16:04:12, time: 1.243, data_time: 0.288, memory: 8758, decode.loss_ce: 0.1362, decode.acc_seg: 77.9504, aux.loss_ce: 0.0711, aux.acc_seg: 76.5041, loss: 0.2073\n",
      "2021-11-16 06:28:43,913 - mmseg - INFO - Saving checkpoint at 4336 iterations\n",
      "2021-11-16 06:28:45,412 - mmseg - INFO - Iter [4336/216800]\tlr: 1.000e-04, eta: 2 days, 15:01:48, time: 0.964, data_time: 0.006, memory: 8758, decode.loss_ce: 0.1344, decode.acc_seg: 77.6207, aux.loss_ce: 0.0701, aux.acc_seg: 76.1967, loss: 0.2044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 1908/1908, 12.6 task/s, elapsed: 152s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 06:31:17,547 - mmseg - INFO - per class results:\n",
      "2021-11-16 06:31:17,549 - mmseg - INFO - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|       bg      | 95.22 |  98.6 |\n",
      "|      body     |  72.3 | 78.84 |\n",
      "|   right_hand  | 14.21 | 23.77 |\n",
      "|   left_hand   |  12.4 | 23.21 |\n",
      "|    left_leg   |  9.23 | 15.32 |\n",
      "|   right_reg   |  4.47 |  7.16 |\n",
      "|  right_thigh  |  7.66 | 13.23 |\n",
      "|   left_thigh  |  9.95 |  19.4 |\n",
      "|   right_calf  |  5.93 | 10.53 |\n",
      "|   left_calf   |  9.14 | 16.79 |\n",
      "|    left_arm   | 12.18 | 22.93 |\n",
      "|   right_arm   | 13.74 | 21.99 |\n",
      "|  left_forearm | 10.72 | 19.45 |\n",
      "| right_forearm | 11.82 | 20.31 |\n",
      "|      head     | 65.27 | 72.29 |\n",
      "+---------------+-------+-------+\n",
      "2021-11-16 06:31:17,549 - mmseg - INFO - Summary:\n",
      "2021-11-16 06:31:17,550 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 87.74 | 23.62 | 30.92 |\n",
      "+-------+-------+-------+\n",
      "2021-11-16 06:31:17,558 - mmseg - INFO - Iter(val) [1908]\taAcc: 0.8774, mIoU: 0.2362, mAcc: 0.3092, IoU.bg: 0.9522, IoU.body: 0.7230, IoU.right_hand: 0.1421, IoU.left_hand: 0.1240, IoU.left_leg: 0.0923, IoU.right_reg: 0.0447, IoU.right_thigh: 0.0766, IoU.left_thigh: 0.0995, IoU.right_calf: 0.0593, IoU.left_calf: 0.0914, IoU.left_arm: 0.1218, IoU.right_arm: 0.1374, IoU.left_forearm: 0.1072, IoU.right_forearm: 0.1182, IoU.head: 0.6527, Acc.bg: 0.9860, Acc.body: 0.7884, Acc.right_hand: 0.2377, Acc.left_hand: 0.2321, Acc.left_leg: 0.1532, Acc.right_reg: 0.0716, Acc.right_thigh: 0.1323, Acc.left_thigh: 0.1940, Acc.right_calf: 0.1053, Acc.left_calf: 0.1679, Acc.left_arm: 0.2293, Acc.right_arm: 0.2199, Acc.left_forearm: 0.1945, Acc.right_forearm: 0.2031, Acc.head: 0.7229\n"
     ]
    }
   ],
   "source": [
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7c999-1404-4243-8bf6-028efeca45a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
